"""
KREA Realtime Video - æœ¬åœ° GPU ç‰ˆæœ¬
ä½¿ç”¨æœ¬åœ° GPU è€Œä¸æ˜¯ FAL API
"""
import os
import asyncio
import json
from typing import Optional
from fastapi import FastAPI, Request, WebSocket
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
import msgpack

# å¯¼å…¥æœ¬åœ°æ¨ç†æ¨¡å—
from local_inference import get_model
from config import MODEL_PATH, QUANTIZATION

app = FastAPI()
templates = Jinja2Templates(directory=".")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Add CSP middleware
class CSPMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)
        if "text/html" in response.headers.get("content-type", ""):
            response.headers["Content-Security-Policy"] = (
                "default-src 'self'; "
                "script-src 'self' 'unsafe-inline' 'unsafe-eval'; "
                "style-src 'self' 'unsafe-inline' https://fonts.googleapis.com; "
                "font-src 'self' https://fonts.gstatic.com; "
                "connect-src 'self' wss: https:; "
                "img-src 'self' data: blob:; "
                "media-src 'self' blob:;"
            )
        return response

app.add_middleware(CSPMiddleware)

# Track active WebSocket connections
active_websockets = set()

# å…¨å±€æ¨¡å‹å®ä¾‹
model = None

def load_model_on_startup():
    """å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹"""
    global model
    print("")
    print("=" * 60)
    print("ğŸ”¥ Loading KREA model to GPU...")
    if MODEL_PATH:
        print(f"   From: {MODEL_PATH}")
    else:
        print("   From: HuggingFace (krea/krea-realtime-video)")
    if QUANTIZATION:
        print(f"   Quantization: {QUANTIZATION.upper()}")
    else:
        print("   Quantization: None (full precision)")
    print("   This will take 1-2 minutes on first run")
    print("=" * 60)
    print("")
    model = get_model(model_path=MODEL_PATH, quantization=QUANTIZATION)
    print("")
    print("=" * 60)
    print("âœ… Model loaded successfully!")
    print("ğŸŒ Server is ready to accept connections")
    print("=" * 60)
    print("")

async def cleanup_expired_sessions():
    """åå°ä»»åŠ¡ï¼šå®šæœŸæ¸…ç†è¶…æ—¶çš„ HTTP sessions"""
    while True:
        await asyncio.sleep(30)  # æ¯ 30 ç§’æ£€æŸ¥ä¸€æ¬¡
        
        expired_sessions = []
        with session_lock:
            for session_id, session in list(active_sessions.items()):
                if session.is_expired():
                    expired_sessions.append((session_id, session))
        
        # æ¸…ç†è¶…æ—¶çš„ sessions
        for session_id, session in expired_sessions:
            with session_lock:
                if session_id in active_sessions:
                    # æ¸…ç†æ¨ç†æ˜¾å­˜
                    if hasattr(session.model, 'cleanup_inference'):
                        session.model.cleanup_inference()
                    del active_sessions[session_id]
                    print(f"[Cleanup] Session {session_id} expired and cleaned (timeout: {SESSION_TIMEOUT}s)")

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„äº‹ä»¶"""
    import asyncio
    # åœ¨åå°çº¿ç¨‹åŠ è½½æ¨¡å‹ï¼Œé¿å…é˜»å¡å¯åŠ¨
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(None, load_model_on_startup)
    
    # å¯åŠ¨åå°æ¸…ç†ä»»åŠ¡
    asyncio.create_task(cleanup_expired_sessions())


@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    """Home page"""
    return templates.TemplateResponse("index.html", {"request": request})


@app.get("/health")
async def health():
    """Health check endpoint"""
    return {
        "status": "ok",
        "mode": "local_gpu",
        "model_loaded": model is not None,
        "ready": model is not None
    }


@app.post("/api/clear-cache")
async def clear_inference_cache():
    """æ¸…ç†æ¨ç†ç¼“å­˜ï¼ˆä¸å½±å“æ¨¡å‹åŠ è½½ï¼‰"""
    import gc
    
    cleaned_sessions = 0
    
    # æ¸…ç†æ‰€æœ‰æ´»è·ƒçš„ HTTP sessions
    with session_lock:
        for session_id, session in list(active_sessions.items()):
            if hasattr(session.model, 'cleanup_inference'):
                session.model.cleanup_inference()
            del active_sessions[session_id]
            cleaned_sessions += 1
    
    # æ¸…ç†å…¨å±€æ¨¡å‹çš„æ¨ç†çŠ¶æ€
    if model is not None and hasattr(model, 'cleanup_inference'):
        model.cleanup_inference()
    
    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    gc.collect()
    
    # è·å–å½“å‰æ˜¾å­˜çŠ¶æ€
    import torch
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"[Clear Cache] Sessions cleaned: {cleaned_sessions}, GPU memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved")
        return {
            "status": "ok",
            "sessions_cleaned": cleaned_sessions,
            "gpu_memory_allocated_gb": round(allocated, 2),
            "gpu_memory_reserved_gb": round(reserved, 2)
        }
    
    return {
        "status": "ok",
        "sessions_cleaned": cleaned_sessions
    }


# ============================================================
# RESTful APIï¼ˆHTTP è½®è¯¢æ¨¡å¼ï¼Œæ›¿ä»£ WebSocketï¼‰
# ============================================================
import base64
from fastapi import HTTPException
from fastapi.responses import Response
from pydantic import BaseModel
from typing import Optional, List
import uuid
import threading
import time

# å­˜å‚¨æ´»è·ƒçš„ç”Ÿæˆä¼šè¯
active_sessions = {}
session_lock = threading.Lock()

# Session è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰- è¶…è¿‡æ­¤æ—¶é—´æ²¡æœ‰æ´»åŠ¨çš„ session ä¼šè¢«è‡ªåŠ¨æ¸…ç†
SESSION_TIMEOUT = 60

class StartGenerationRequest(BaseModel):
    prompt: str
    num_blocks: int = 25
    num_denoising_steps: int = 4
    strength: float = 0.45
    seed: Optional[int] = None
    start_frame: Optional[str] = None  # base64 encoded

class FrameRequest(BaseModel):
    session_id: str
    image: Optional[str] = None  # base64 encoded
    prompt: Optional[str] = None
    strength: Optional[float] = None

class GenerationSession:
    def __init__(self, session_id: str, model_instance):
        self.session_id = session_id
        self.model = model_instance
        self.initialized = False
        self.current_block = 0
        self.num_blocks = 25
        self.pending_frames = []  # å¾…å‘é€çš„å¸§
        self.lock = threading.Lock()
        self.last_activity = time.time()  # æœ€åæ´»åŠ¨æ—¶é—´
    
    def touch(self):
        """æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´"""
        self.last_activity = time.time()
    
    def is_expired(self):
        """æ£€æŸ¥ session æ˜¯å¦è¶…æ—¶"""
        return time.time() - self.last_activity > SESSION_TIMEOUT

@app.post("/api/generate/start")
async def api_start_generation(req: StartGenerationRequest):
    """å¼€å§‹ç”Ÿæˆä¼šè¯"""
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded yet")
    
    session_id = str(uuid.uuid4())[:8]
    
    # åˆ›å»ºä¼šè¯
    session = GenerationSession(session_id, model)
    session.num_blocks = req.num_blocks
    
    # å¤„ç†èµ·å§‹å¸§
    start_frame = None
    if req.start_frame:
        start_frame_bytes = base64.b64decode(req.start_frame)
        start_frame = model.process_frame_bytes(start_frame_bytes)
    
    # åˆå§‹åŒ–ç”Ÿæˆ
    await asyncio.to_thread(
        model.initialize_generation,
        prompt=req.prompt,
        start_frame=start_frame,
        num_inference_steps=req.num_denoising_steps,
        strength=req.strength,
        seed=req.seed
    )
    
    session.initialized = True
    
    # ç”Ÿæˆç¬¬ä¸€ä¸ª block
    frames = await asyncio.to_thread(
        model.generate_next_block,
        input_frame=None
    )
    
    # è½¬æ¢å¸§ä¸º base64
    for frame in frames:
        frame_bytes = model.frame_to_bytes(frame)
        session.pending_frames.append(base64.b64encode(frame_bytes).decode())
    
    session.current_block = 1
    
    with session_lock:
        active_sessions[session_id] = session
    
    print(f"[HTTP] Session {session_id} started, generated block 0")
    
    return {
        "session_id": session_id,
        "status": "started",
        "frames_ready": len(session.pending_frames)
    }

@app.post("/api/generate/frame")
async def api_generate_frame(req: FrameRequest):
    """å‘é€å¸§å¹¶è·å–ç”Ÿæˆçš„å¸§"""
    with session_lock:
        session = active_sessions.get(req.session_id)
    
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")
    
    # æ›´æ–°æ´»åŠ¨æ—¶é—´
    session.touch()
    
    # æ›´æ–°å‚æ•°
    if req.prompt:
        session.model.prompt = req.prompt
    if req.strength:
        session.model.strength = req.strength
    
    # å¦‚æœæœ‰è¾“å…¥å¸§ï¼Œç”Ÿæˆä¸‹ä¸€ä¸ª block
    if req.image and session.current_block < session.num_blocks:
        input_frame_bytes = base64.b64decode(req.image)
        input_frame = session.model.process_frame_bytes(input_frame_bytes)
        
        frames = await asyncio.to_thread(
            session.model.generate_next_block,
            input_frame=input_frame
        )
        
        with session.lock:
            for frame in frames:
                frame_bytes = session.model.frame_to_bytes(frame)
                session.pending_frames.append(base64.b64encode(frame_bytes).decode())
        
        session.current_block += 1
    
    # è¿”å›å¾…å‘é€çš„å¸§
    with session.lock:
        frames_to_send = session.pending_frames[:5]  # æ¯æ¬¡æœ€å¤šè¿”å›5å¸§
        session.pending_frames = session.pending_frames[5:]
    
    return {
        "session_id": req.session_id,
        "current_block": session.current_block,
        "total_blocks": session.num_blocks,
        "frames": frames_to_send,
        "complete": session.current_block >= session.num_blocks and len(session.pending_frames) == 0
    }

@app.get("/api/generate/frames/{session_id}")
async def api_get_frames(session_id: str, count: int = 5):
    """è·å–ç”Ÿæˆçš„å¸§ï¼ˆä¸å‘é€æ–°è¾“å…¥ï¼‰"""
    with session_lock:
        session = active_sessions.get(session_id)
    
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")
    
    # æ›´æ–°æ´»åŠ¨æ—¶é—´
    session.touch()
    
    with session.lock:
        frames_to_send = session.pending_frames[:count]
        session.pending_frames = session.pending_frames[count:]
    
    return {
        "session_id": session_id,
        "frames": frames_to_send,
        "frames_remaining": len(session.pending_frames),
        "complete": session.current_block >= session.num_blocks and len(session.pending_frames) == 0
    }

@app.post("/api/generate/stop/{session_id}")
async def api_stop_generation(session_id: str):
    """åœæ­¢ç”Ÿæˆä¼šè¯"""
    with session_lock:
        if session_id in active_sessions:
            session = active_sessions[session_id]
            # æ¸…ç†æ¨ç†æ˜¾å­˜
            if hasattr(session.model, 'cleanup_inference'):
                session.model.cleanup_inference()
            del active_sessions[session_id]
            print(f"[HTTP] Session {session_id} stopped, memory cleaned")
            return {"status": "stopped"}
    
    return {"status": "not_found"}


@app.websocket("/ws/video-gen")
async def websocket_video_gen(websocket: WebSocket):
    """WebSocket å¤„ç† - ä½¿ç”¨æœ¬åœ° GPU"""
    await websocket.accept()
    
    active_websockets.add(websocket)
    print(f"WebSocket connected. Active connections: {len(active_websockets)}")
    
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
        if model is None:
            await websocket.close(code=1011, reason="Model not loaded yet, please wait...")
            return
        
        inference_model = model
        
        # å‘é€ ready ä¿¡å·
        await websocket.send_text(json.dumps({"status": "ready"}))
        print("Sent ready signal to client")
        
        # åˆå§‹åŒ–æ ‡å¿—
        initialized = False
        prompt = ""
        num_blocks = 25
        current_block = 0
        
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            data = await websocket.receive_bytes()
            
            # è§£æ msgpack
            message = msgpack.unpackb(data, raw=False)
            
            # åˆå§‹åŒ–å‚æ•°
            if not initialized and "prompt" in message:
                prompt = message.get("prompt", "")
                num_blocks = message.get("num_blocks", 25)
                num_inference_steps = message.get("num_denoising_steps", 4)
                strength = message.get("strength", 0.45)
                seed = message.get("seed")
                start_frame = message.get("start_frame")  # å¯èƒ½æ˜¯ bytes
                
                print(f"Initializing: prompt='{prompt}', num_blocks={num_blocks}")
                
                # åˆå§‹åŒ–ç”Ÿæˆ
                await asyncio.to_thread(
                    inference_model.initialize_generation,
                    prompt=prompt,
                    start_frame=start_frame,
                    num_inference_steps=num_inference_steps,
                    strength=strength,
                    seed=seed
                )
                
                initialized = True
                current_block = 0
                
                # ç«‹å³ç”Ÿæˆç¬¬ä¸€ä¸ª block
                print(f"Generating block 0/{num_blocks}")
                frames = await asyncio.to_thread(
                    inference_model.generate_next_block,
                    input_frame=None
                )
                
                # å‘é€å¸§
                for frame in frames:
                    frame_bytes = inference_model.frame_to_bytes(frame)
                    await websocket.send_bytes(frame_bytes)
                
                current_block += 1
                
            # æ›´æ–°å‚æ•°ï¼ˆprompt æˆ– num_blocks å˜åŒ–ï¼‰
            elif initialized and "prompt" in message and "image" not in message:
                new_prompt = message.get("prompt")
                new_num_blocks = message.get("num_blocks")
                
                if new_prompt != prompt:
                    print(f"Prompt updated: '{new_prompt}'")
                    prompt = new_prompt
                    inference_model.prompt = prompt
                    
                if new_num_blocks != num_blocks:
                    print(f"num_blocks updated: {new_num_blocks}")
                    num_blocks = new_num_blocks
            
            # æ¥æ”¶è¾“å…¥å¸§ï¼ˆvideo-to-video æˆ– webcam æ¨¡å¼ï¼‰
            elif initialized and "image" in message:
                input_frame_bytes = message["image"]
                strength = message.get("strength", 0.45)
                
                # æ›´æ–° strength
                inference_model.strength = strength
                
                # å¯èƒ½è¿˜æœ‰ prompt æ›´æ–°
                if "prompt" in message:
                    inference_model.prompt = message["prompt"]
                if "num_blocks" in message:
                    num_blocks = message["num_blocks"]
                
                # ç”Ÿæˆä¸‹ä¸€ä¸ª block
                if current_block < num_blocks:
                    input_frame = inference_model.process_frame_bytes(input_frame_bytes)
                    
                    frames = await asyncio.to_thread(
                        inference_model.generate_next_block,
                        input_frame=input_frame
                    )
                    
                    # å‘é€å¸§
                    for frame in frames:
                        frame_bytes = inference_model.frame_to_bytes(frame)
                        await websocket.send_bytes(frame_bytes)
                    
                    current_block += 1
                    
                    if current_block >= num_blocks:
                        print(f"Generation complete: {current_block} blocks")
                        
    except Exception as e:
        print(f"WebSocket error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        active_websockets.discard(websocket)
        # æ¸…ç†æ¨ç†æ˜¾å­˜
        if model is not None and hasattr(model, 'cleanup_inference'):
            model.cleanup_inference()
            print("Inference memory cleaned")
        print(f"WebSocket disconnected. Active connections: {len(active_websockets)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=7860)
