"""
INT8 é‡åŒ–åŠ è½½
ä½¿ç”¨ torchao åº“è¿›è¡ŒåŠ¨æ€é‡åŒ–
éœ€è¦ ~28GB æ˜¾å­˜
"""
import torch
import gc


def load_int8(pipe, repo_id, device, dtype):
    """INT8 é‡åŒ–åŠ è½½
    
    Args:
        pipe: ModularPipeline å®ä¾‹
        repo_id: æ¨¡å‹ä»“åº“ ID
        device: ç›®æ ‡è®¾å¤‡
        dtype: åŸºç¡€æ•°æ®ç±»å‹
    
    Returns:
        åŠ è½½å®Œæˆçš„ pipe
    """
    print("ğŸ”§ å¯ç”¨ INT8 é‡åŒ– (torchao)...")
    
    try:
        from torchao.quantization import quantize_, int8_dynamic_activation_int8_weight
    except ImportError as e:
        print("   âŒ ç¼ºå°‘ torchao ä¾èµ–")
        print("   è¯·å®‰è£…: pip install torchao")
        raise RuntimeError(f"INT8 é‡åŒ–å¤±è´¥ï¼Œç¼ºå°‘ä¾èµ–: {e}")
    
    # 1. æ ‡å‡†åŠ è½½æ‰€æœ‰ç»„ä»¶
    print("   [1/3] æ­£åœ¨åŠ è½½æ¨¡å‹ç»„ä»¶...")
    pipe.load_components(
        trust_remote_code=True,
        device_map=device,
        torch_dtype={"default": dtype, "vae": torch.float16},
    )
    
    # 2. å®šä¹‰é‡åŒ–è¿‡æ»¤å™¨ï¼šåªé‡åŒ– Linear å±‚
    def linear_only_filter(module, name):
        return isinstance(module, torch.nn.Linear)
    
    # 3. å¯¹ transformer è¿›è¡Œé‡åŒ–
    print("   [2/3] æ­£åœ¨é‡åŒ– transformer (ä»… Linear å±‚)...")
    print("   ä½¿ç”¨ INT8 åŠ¨æ€é‡åŒ– (é¢„è®¡æ˜¾å­˜ ~28GB)")
    
    quantize_(
        pipe.transformer, 
        int8_dynamic_activation_int8_weight(),
        filter_fn=linear_only_filter
    )
    
    # 4. æ¸…ç†æ˜¾å­˜å’Œ CPU å†…å­˜
    print("   [3/3] æ¸…ç†æ˜¾å­˜ç¼“å­˜...")
    gc.collect()
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
    
    # é‡åŒ–æ¨¡å¼ä¸‹è·³è¿‡ fuse_projections
    print("   âš ï¸  é‡åŒ–æ¨¡å¼ä¸‹è·³è¿‡ fuse_projectionsï¼ˆä¸å…¼å®¹ï¼‰")
    
    print("   âœ… INT8 é‡åŒ–å®Œæˆ")
    
    # è®¾ç½® Text Encoder Offload å¹¶ç«‹å³æ‰§è¡Œï¼ˆç”¨äºé‡Šæ”¾æ˜¾å­˜ç»™ KV cacheï¼‰
    from .offload import setup_text_encoder_offload, offload_text_encoder
    pipe = setup_text_encoder_offload(pipe)
    offload_text_encoder(pipe)  # ç«‹å³ offloadï¼Œé‡Šæ”¾ ~10GB æ˜¾å­˜
    
    return pipe
